{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d9a4e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ğŸ“ EduDiff XL â€” Generador de Material Educativo con IA Generativa\n",
    "\n",
    "## EA3: GeneraciÃ³n de Contenido con Inteligencia Artificial Generativa\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“‹ InformaciÃ³n del Proyecto\n",
    "\n",
    "| Campo | DescripciÃ³n |\n",
    "|-------|-------------|\n",
    "| **Proyecto** | EduDiff XL - Sistema de GeneraciÃ³n de Material Educativo |\n",
    "| **Dominio** | EducaciÃ³n |\n",
    "| **Arquitectura** | Modelos de DifusiÃ³n (Stable Diffusion XL + ControlNet) |\n",
    "| **Framework** | Diffusers (Hugging Face), PyTorch |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Objetivos del Sistema\n",
    "\n",
    "1. **Objetivo Principal:** Desarrollar una aplicaciÃ³n de IA generativa que permita a docentes y creadores de contenido educativo generar material visual de alta calidad de manera rÃ¡pida y accesible.\n",
    "\n",
    "2. **Objetivos EspecÃ­ficos:**\n",
    "   - Implementar un modelo de difusiÃ³n (Stable Diffusion XL) para generaciÃ³n de imÃ¡genes educativas\n",
    "   - Integrar ControlNet para control preciso sobre la composiciÃ³n de las imÃ¡genes\n",
    "   - Proporcionar una interfaz intuitiva accesible para usuarios sin conocimientos tÃ©cnicos\n",
    "   - Ofrecer plantillas y estilos optimizados para diferentes Ã¡reas educativas\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š Marco TeÃ³rico\n",
    "\n",
    "#### Modelos de DifusiÃ³n\n",
    "Los modelos de difusiÃ³n son una clase de modelos generativos que aprenden a generar datos mediante un proceso de \"denoising\" (eliminaciÃ³n de ruido). El proceso consiste en:\n",
    "\n",
    "1. **Proceso Forward (DifusiÃ³n):** Agregar ruido gaussiano progresivamente a los datos hasta obtener ruido puro.\n",
    "2. **Proceso Reverse (GeneraciÃ³n):** Aprender a revertir este proceso, eliminando el ruido paso a paso para generar nuevas muestras.\n",
    "\n",
    "La ecuaciÃ³n fundamental del proceso de difusiÃ³n es:\n",
    "$$q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1-\\beta_t}x_{t-1}, \\beta_t I)$$\n",
    "\n",
    "Donde $\\beta_t$ es el schedule de varianza que controla la cantidad de ruido aÃ±adido en cada paso.\n",
    "\n",
    "#### Stable Diffusion XL (SDXL)\n",
    "SDXL es la versiÃ³n mejorada de Stable Diffusion con:\n",
    "- **ResoluciÃ³n nativa de 1024x1024 pÃ­xeles**\n",
    "- **Arquitectura U-Net mÃ¡s grande** con mÃ¡s parÃ¡metros\n",
    "- **Mejor comprensiÃ³n del texto** mediante dos encoders de texto (OpenCLIP y CLIP)\n",
    "- **Condicionamiento por tamaÃ±o** para mejor control de la composiciÃ³n\n",
    "\n",
    "#### ControlNet\n",
    "ControlNet aÃ±ade control espacial a los modelos de difusiÃ³n mediante:\n",
    "- **Canny:** Control basado en detecciÃ³n de bordes\n",
    "- **Depth:** Control basado en mapas de profundidad\n",
    "- **Lineart:** Control basado en lÃ­neas de contorno\n",
    "- **Sketch:** Control basado en bocetos\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”§ JustificaciÃ³n MetodolÃ³gica\n",
    "\n",
    "Se eligieron modelos de difusiÃ³n (especÃ­ficamente SDXL) sobre otras arquitecturas como GANs por las siguientes razones:\n",
    "\n",
    "| Aspecto | GANs | Modelos de DifusiÃ³n |\n",
    "|---------|------|---------------------|\n",
    "| Estabilidad de entrenamiento | ProblemÃ¡tica (mode collapse) | Estable |\n",
    "| Diversidad de salidas | Limitada | Alta |\n",
    "| Control sobre la generaciÃ³n | DifÃ­cil | Excelente (via conditioning) |\n",
    "| Calidad de imagen | Alta | Muy alta |\n",
    "| Facilidad de uso con prompts | Limitada | Nativa |\n",
    "\n",
    "**Ventaja clave:** Los modelos de difusiÃ³n permiten control fino mediante texto (prompts) y condicionamientos adicionales (ControlNet), ideal para el contexto educativo donde se requiere especificidad en el contenido generado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9df9a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 1: INSTALACIÃ“N DE DEPENDENCIAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Ejecutar solo una vez al inicio de la sesiÃ³n\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install diffusers>=0.35.1 transformers>=4.40.0 accelerate safetensors\n",
    "!pip install gradio>=4.44.1 huggingface_hub>=0.25.0\n",
    "!pip install pytorch-fid torchmetrics scipy\n",
    "!pip install matplotlib seaborn pandas numpy pillow\n",
    "!pip install opencv-python scikit-image\n",
    "\n",
    "print(\"âœ… Dependencias instaladas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 2: IMPORTACIÃ“N DE LIBRERÃAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "from diffusers import (\n",
    "    StableDiffusionXLPipeline,\n",
    "    StableDiffusionPipeline,\n",
    "    ControlNetModel,\n",
    "    StableDiffusionXLControlNetPipeline,\n",
    "    DPMSolverMultistepScheduler,\n",
    "    DDPMScheduler\n",
    ")\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ConfiguraciÃ³n de visualizaciÃ³n\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Verificar GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"ğŸ“ Dispositivo: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"ğŸ”§ PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84662bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 3: CONFIGURACIÃ“N DEL MODELO Y DIRECTORIOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# ConfiguraciÃ³n de modelos\n",
    "MODEL_CONFIG = {\n",
    "    \"sdxl\": {\n",
    "        \"id\": \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "        \"name\": \"Stable Diffusion XL 1.0\",\n",
    "        \"resolution\": (1024, 1024),\n",
    "        \"description\": \"Modelo principal de alta calidad\"\n",
    "    },\n",
    "    \"sd15\": {\n",
    "        \"id\": \"runwayml/stable-diffusion-v1-5\", \n",
    "        \"name\": \"Stable Diffusion 1.5\",\n",
    "        \"resolution\": (512, 512),\n",
    "        \"description\": \"Modelo ligero para experimentaciÃ³n rÃ¡pida\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ControlNet disponibles\n",
    "CONTROLNET_CONFIG = {\n",
    "    \"canny\": \"diffusers/controlnet-canny-sdxl-1.0\",\n",
    "    \"depth\": \"diffusers/controlnet-depth-sdxl-1.0\",\n",
    "    \"lineart\": \"xinsir/controlnet-lineart-sdxl-1.0\",\n",
    "    \"sketch\": \"xinsir/controlnet-sketch-sdxl-1.0\"\n",
    "}\n",
    "\n",
    "# Estilos educativos\n",
    "EDUCATION_STYLES = {\n",
    "    \"infografia\": {\n",
    "        \"prompt_suffix\": \"professional infographic, clean design, labeled diagram, white background, educational, clear typography\",\n",
    "        \"negative\": \"blurry, text errors, cluttered, confusing\"\n",
    "    },\n",
    "    \"ilustracion\": {\n",
    "        \"prompt_suffix\": \"digital illustration, vibrant colors, educational style, child-friendly\",\n",
    "        \"negative\": \"scary, dark, complex, realistic photo\"\n",
    "    },\n",
    "    \"cientifico\": {\n",
    "        \"prompt_suffix\": \"scientific illustration, detailed anatomy, textbook quality, precise rendering, labeled parts\",\n",
    "        \"negative\": \"cartoon, simplified, artistic interpretation\"\n",
    "    },\n",
    "    \"diagrama\": {\n",
    "        \"prompt_suffix\": \"technical diagram, clean lines, organized layout, flowchart style, clear connections\",\n",
    "        \"negative\": \"realistic, photographic, cluttered\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Crear directorios de trabajo\n",
    "OUTPUT_DIR = '/content/edudiff_output'\n",
    "EXPERIMENTS_DIR = os.path.join(OUTPUT_DIR, 'experiments')\n",
    "METRICS_DIR = os.path.join(OUTPUT_DIR, 'metrics')\n",
    "PORTFOLIO_DIR = os.path.join(OUTPUT_DIR, 'portfolio')\n",
    "\n",
    "for dir_path in [OUTPUT_DIR, EXPERIMENTS_DIR, METRICS_DIR, PORTFOLIO_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(\"ğŸ“ Directorios creados:\")\n",
    "print(f\"   - Output: {OUTPUT_DIR}\")\n",
    "print(f\"   - Experiments: {EXPERIMENTS_DIR}\")\n",
    "print(f\"   - Metrics: {METRICS_DIR}\")\n",
    "print(f\"   - Portfolio: {PORTFOLIO_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd788af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 4: CARGA DEL MODELO DE DIFUSIÃ“N\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def load_pipeline(model_type: str = \"sd15\", use_optimizations: bool = True):\n",
    "    \"\"\"\n",
    "    Carga el pipeline de Stable Diffusion.\n",
    "    \n",
    "    Args:\n",
    "        model_type: \"sdxl\" para alta calidad, \"sd15\" para experimentaciÃ³n rÃ¡pida\n",
    "        use_optimizations: Aplicar optimizaciones de memoria\n",
    "    \n",
    "    Returns:\n",
    "        Pipeline configurado y listo para usar\n",
    "    \"\"\"\n",
    "    config = MODEL_CONFIG[model_type]\n",
    "    print(f\"ğŸ”„ Cargando {config['name']}...\")\n",
    "    \n",
    "    dtype = torch.float16 if device == 'cuda' else torch.float32\n",
    "    \n",
    "    if model_type == \"sdxl\":\n",
    "        pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "            config[\"id\"],\n",
    "            torch_dtype=dtype,\n",
    "            use_safetensors=True,\n",
    "            variant=\"fp16\" if device == 'cuda' else None\n",
    "        )\n",
    "    else:\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            config[\"id\"],\n",
    "            torch_dtype=dtype,\n",
    "            use_safetensors=True\n",
    "        )\n",
    "        pipe.safety_checker = None\n",
    "    \n",
    "    # Optimizar scheduler\n",
    "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        pipe = pipe.to('cuda')\n",
    "        if use_optimizations:\n",
    "            try:\n",
    "                pipe.enable_xformers_memory_efficient_attention()\n",
    "                print(\"âœ… xFormers habilitado\")\n",
    "            except:\n",
    "                print(\"âš ï¸ xFormers no disponible, usando atenciÃ³n estÃ¡ndar\")\n",
    "    \n",
    "    print(f\"âœ… Modelo cargado en {device.upper()}\")\n",
    "    return pipe\n",
    "\n",
    "# Cargar modelo (SD 1.5 para experimentaciÃ³n rÃ¡pida en Colab)\n",
    "pipe = load_pipeline(\"sd15\", use_optimizations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9180f",
   "metadata": {},
   "source": [
    "## ğŸ›ï¸ ImplementaciÃ³n de ControlNet\n",
    "\n",
    "ControlNet permite aÃ±adir **control espacial** a la generaciÃ³n de imÃ¡genes mediante diferentes tipos de condicionamiento:\n",
    "\n",
    "| Tipo | DescripciÃ³n | Uso Educativo |\n",
    "|------|-------------|---------------|\n",
    "| **Canny** | DetecciÃ³n de bordes | Convertir bocetos en ilustraciones detalladas |\n",
    "| **Depth** | Mapas de profundidad | Mantener composiciÃ³n 3D de referencias |\n",
    "| **Lineart** | LÃ­neas de contorno | Colorear diagramas dibujados a mano |\n",
    "| **Sketch** | Bocetos simples | Transformar ideas rÃ¡pidas en material profesional |\n",
    "\n",
    "A continuaciÃ³n se implementa ControlNet para demostrar el control preciso sobre la composiciÃ³n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57175182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA: IMPLEMENTACIÃ“N DE CONTROLNET\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_controlnet_pipeline(controlnet_type: str = \"canny\"):\n",
    "    \"\"\"\n",
    "    Carga el pipeline de Stable Diffusion con ControlNet.\n",
    "    \n",
    "    Args:\n",
    "        controlnet_type: Tipo de ControlNet (\"canny\", \"depth\", \"lineart\", \"sketch\")\n",
    "    \n",
    "    Returns:\n",
    "        Pipeline con ControlNet configurado\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”„ Cargando ControlNet ({controlnet_type})...\")\n",
    "    \n",
    "    # Cargar modelo ControlNet\n",
    "    controlnet = ControlNetModel.from_pretrained(\n",
    "        CONTROLNET_CONFIG[controlnet_type],\n",
    "        torch_dtype=torch.float16 if device == 'cuda' else torch.float32,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "    \n",
    "    # Cargar pipeline con ControlNet\n",
    "    pipe_controlnet = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
    "        MODEL_CONFIG[\"sdxl\"][\"id\"],\n",
    "        controlnet=controlnet,\n",
    "        torch_dtype=torch.float16 if device == 'cuda' else torch.float32,\n",
    "        use_safetensors=True,\n",
    "        variant=\"fp16\" if device == 'cuda' else None\n",
    "    )\n",
    "    \n",
    "    # Configurar scheduler optimizado\n",
    "    pipe_controlnet.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "        pipe_controlnet.scheduler.config\n",
    "    )\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        pipe_controlnet = pipe_controlnet.to('cuda')\n",
    "        try:\n",
    "            pipe_controlnet.enable_xformers_memory_efficient_attention()\n",
    "            print(\"âœ… xFormers habilitado para ControlNet\")\n",
    "        except:\n",
    "            print(\"âš ï¸ xFormers no disponible\")\n",
    "    \n",
    "    print(f\"âœ… ControlNet ({controlnet_type}) cargado exitosamente\")\n",
    "    return pipe_controlnet\n",
    "\n",
    "\n",
    "def apply_canny_edge_detection(image: Image.Image, low_threshold: int = 100, high_threshold: int = 200) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Aplica detecciÃ³n de bordes Canny a una imagen.\n",
    "    \n",
    "    Args:\n",
    "        image: Imagen PIL de entrada\n",
    "        low_threshold: Umbral bajo para Canny\n",
    "        high_threshold: Umbral alto para Canny\n",
    "    \n",
    "    Returns:\n",
    "        Imagen con bordes detectados\n",
    "    \"\"\"\n",
    "    # Convertir a array numpy\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # Convertir a escala de grises si es necesario\n",
    "    if len(img_array.shape) == 3:\n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img_array\n",
    "    \n",
    "    # Aplicar Canny\n",
    "    edges = cv2.Canny(gray, low_threshold, high_threshold)\n",
    "    \n",
    "    # Convertir de vuelta a imagen RGB\n",
    "    edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    return Image.fromarray(edges_rgb)\n",
    "\n",
    "\n",
    "def generate_with_controlnet(\n",
    "    prompt: str,\n",
    "    control_image: Image.Image,\n",
    "    controlnet_type: str = \"canny\",\n",
    "    style: str = \"infografia\",\n",
    "    num_inference_steps: int = 30,\n",
    "    guidance_scale: float = 7.5,\n",
    "    controlnet_conditioning_scale: float = 0.8,\n",
    "    seed: int = -1\n",
    ") -> Tuple[Image.Image, Image.Image, Dict]:\n",
    "    \"\"\"\n",
    "    Genera imagen educativa usando ControlNet para control de composiciÃ³n.\n",
    "    \n",
    "    Args:\n",
    "        prompt: DescripciÃ³n del contenido\n",
    "        control_image: Imagen de control (boceto, diagrama, etc.)\n",
    "        controlnet_type: Tipo de ControlNet a usar\n",
    "        style: Estilo educativo\n",
    "        num_inference_steps: Pasos de inferencia\n",
    "        guidance_scale: Escala de guÃ­a\n",
    "        controlnet_conditioning_scale: Fuerza del control (0.0-1.0)\n",
    "        seed: Semilla para reproducibilidad\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (imagen_generada, imagen_control_procesada, metadatos)\n",
    "    \"\"\"\n",
    "    # Configurar semilla\n",
    "    if seed == -1:\n",
    "        seed = torch.randint(0, 2**32 - 1, (1,)).item()\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    \n",
    "    # Procesar imagen de control segÃºn tipo\n",
    "    if controlnet_type == \"canny\":\n",
    "        processed_control = apply_canny_edge_detection(control_image)\n",
    "    else:\n",
    "        processed_control = control_image\n",
    "    \n",
    "    # Redimensionar a resoluciÃ³n SDXL\n",
    "    processed_control = processed_control.resize((1024, 1024), Image.LANCZOS)\n",
    "    \n",
    "    # Construir prompt\n",
    "    style_config = EDUCATION_STYLES.get(style, EDUCATION_STYLES[\"infografia\"])\n",
    "    full_prompt = f\"{prompt}, {style_config['prompt_suffix']}\"\n",
    "    negative_prompt = style_config['negative'] + \", watermark, bad quality, blurry\"\n",
    "    \n",
    "    # Cargar pipeline si no existe\n",
    "    global pipe_controlnet\n",
    "    try:\n",
    "        pipe_controlnet\n",
    "    except NameError:\n",
    "        pipe_controlnet = load_controlnet_pipeline(controlnet_type)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Generar con ControlNet\n",
    "    with torch.autocast(device):\n",
    "        result = pipe_controlnet(\n",
    "            prompt=full_prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=processed_control,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            controlnet_conditioning_scale=controlnet_conditioning_scale,\n",
    "            generator=generator\n",
    "        )\n",
    "    \n",
    "    generation_time = time.time() - start_time\n",
    "    \n",
    "    metadata = {\n",
    "        \"prompt\": prompt,\n",
    "        \"controlnet_type\": controlnet_type,\n",
    "        \"style\": style,\n",
    "        \"steps\": num_inference_steps,\n",
    "        \"guidance\": guidance_scale,\n",
    "        \"controlnet_scale\": controlnet_conditioning_scale,\n",
    "        \"seed\": seed,\n",
    "        \"generation_time\": round(generation_time, 2)\n",
    "    }\n",
    "    \n",
    "    return result.images[0], processed_control, metadata\n",
    "\n",
    "print(\"âœ… Funciones de ControlNet definidas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA: DEMOSTRACIÃ“N DE CONTROLNET CON BOCETO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ¨ DEMOSTRACIÃ“N DE CONTROLNET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Crear un boceto simple programÃ¡ticamente (simulando un dibujo de usuario)\n",
    "def create_sample_sketch(size: int = 512) -> Image.Image:\n",
    "    \"\"\"Crea un boceto de ejemplo de una cÃ©lula para demostraciÃ³n.\"\"\"\n",
    "    import numpy as np\n",
    "    from PIL import Image, ImageDraw\n",
    "    \n",
    "    # Crear imagen blanca\n",
    "    img = Image.new('RGB', (size, size), 'white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Dibujar forma de cÃ©lula (elipse grande)\n",
    "    margin = 50\n",
    "    draw.ellipse([margin, margin, size-margin, size-margin], outline='black', width=3)\n",
    "    \n",
    "    # Dibujar nÃºcleo (cÃ­rculo interior)\n",
    "    nucleus_size = size // 4\n",
    "    center = size // 2\n",
    "    draw.ellipse([\n",
    "        center - nucleus_size, center - nucleus_size,\n",
    "        center + nucleus_size, center + nucleus_size\n",
    "    ], outline='black', width=2)\n",
    "    \n",
    "    # Dibujar algunas mitocondrias (elipses pequeÃ±as)\n",
    "    mitochondria_positions = [\n",
    "        (100, 200), (350, 150), (120, 350), (380, 380)\n",
    "    ]\n",
    "    for x, y in mitochondria_positions:\n",
    "        draw.ellipse([x, y, x+60, y+25], outline='black', width=2)\n",
    "    \n",
    "    # Dibujar ribosomas (puntos pequeÃ±os)\n",
    "    for i in range(20):\n",
    "        x = np.random.randint(80, size-80)\n",
    "        y = np.random.randint(80, size-80)\n",
    "        # Evitar el nÃºcleo\n",
    "        dist_from_center = np.sqrt((x - center)**2 + (y - center)**2)\n",
    "        if dist_from_center > nucleus_size + 20:\n",
    "            draw.ellipse([x-3, y-3, x+3, y+3], fill='black')\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Crear boceto de ejemplo\n",
    "print(\"ğŸ“ Creando boceto de ejemplo...\")\n",
    "sample_sketch = create_sample_sketch(512)\n",
    "\n",
    "# Mostrar boceto\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(sample_sketch)\n",
    "plt.title(\"Boceto de entrada (simulado)\", fontsize=12)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Guardar boceto\n",
    "sketch_path = os.path.join(EXPERIMENTS_DIR, \"controlnet_input_sketch.png\")\n",
    "sample_sketch.save(sketch_path)\n",
    "print(f\"ğŸ“ Boceto guardado en: {sketch_path}\")\n",
    "\n",
    "# NOTA: La generaciÃ³n con ControlNet requiere mÃ¡s VRAM\n",
    "# En Colab gratuito, puede ser necesario usar la versiÃ³n sin ControlNet\n",
    "# o actualizar a Colab Pro para mÃ¡s recursos\n",
    "\n",
    "print(\"\\nâš ï¸ NOTA: ControlNet + SDXL requiere ~16GB VRAM\")\n",
    "print(\"   Para ejecutar en Colab gratuito, usa T4 GPU o superior\")\n",
    "print(\"   Si hay errores de memoria, continÃºa con las celdas siguientes\")\n",
    "\n",
    "# Intentar generaciÃ³n con ControlNet (comentado por defecto para evitar errores de memoria)\n",
    "\"\"\"\n",
    "# Descomentar para ejecutar con GPU suficiente:\n",
    "\n",
    "# Liberar memoria antes de cargar ControlNet\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "generated_image, control_processed, metadata = generate_with_controlnet(\n",
    "    prompt=\"Diagrama detallado de cÃ©lula animal con orgÃ¡nulos etiquetados\",\n",
    "    control_image=sample_sketch,\n",
    "    controlnet_type=\"canny\",\n",
    "    style=\"cientifico\",\n",
    "    num_inference_steps=25,\n",
    "    guidance_scale=7.5,\n",
    "    controlnet_conditioning_scale=0.7,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Visualizar resultados\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(sample_sketch)\n",
    "axes[0].set_title(\"1. Boceto Original\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(control_processed)\n",
    "axes[1].set_title(\"2. Bordes Canny Detectados\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(generated_image)\n",
    "axes[2].set_title(\"3. Imagen Generada con ControlNet\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(\"ControlNet: Boceto â†’ IlustraciÃ³n Educativa\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(EXPERIMENTS_DIR, \"controlnet_demo.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\\\nâœ… GeneraciÃ³n con ControlNet completada en {metadata['generation_time']}s\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nâœ… DemostraciÃ³n de ControlNet configurada\")\n",
    "print(\"   Descomenta el cÃ³digo anterior cuando tengas GPU con suficiente VRAM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d21c4c",
   "metadata": {},
   "source": [
    "## ğŸš€ GeneraciÃ³n con Stable Diffusion XL\n",
    "\n",
    "SDXL ofrece **mayor calidad y resoluciÃ³n** (1024x1024) comparado con SD 1.5 (512x512):\n",
    "\n",
    "| CaracterÃ­stica | SD 1.5 | SDXL |\n",
    "|----------------|--------|------|\n",
    "| **ResoluciÃ³n nativa** | 512Ã—512 | 1024Ã—1024 |\n",
    "| **ParÃ¡metros** | ~860M | ~3.5B |\n",
    "| **Encoders de texto** | 1 (CLIP) | 2 (CLIP + OpenCLIP) |\n",
    "| **VRAM requerida** | ~6GB | ~12GB |\n",
    "| **Calidad de detalle** | Buena | Excelente |\n",
    "\n",
    "A continuaciÃ³n se demuestra la generaciÃ³n con SDXL para contenido educativo de alta calidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA: GENERACIÃ“N CON STABLE DIFFUSION XL (ALTA CALIDAD)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸš€ GENERACIÃ“N CON STABLE DIFFUSION XL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def generate_with_sdxl(\n",
    "    prompt: str,\n",
    "    style: str = \"infografia\",\n",
    "    num_inference_steps: int = 30,\n",
    "    guidance_scale: float = 7.5,\n",
    "    seed: int = -1\n",
    ") -> Tuple[Image.Image, Dict]:\n",
    "    \"\"\"\n",
    "    Genera contenido educativo con Stable Diffusion XL (alta calidad).\n",
    "    \n",
    "    Args:\n",
    "        prompt: DescripciÃ³n del contenido\n",
    "        style: Estilo educativo\n",
    "        num_inference_steps: Pasos de inferencia\n",
    "        guidance_scale: Escala de guÃ­a\n",
    "        seed: Semilla para reproducibilidad\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (imagen, metadatos)\n",
    "    \"\"\"\n",
    "    global pipe_sdxl\n",
    "    \n",
    "    # Cargar SDXL si no estÃ¡ cargado\n",
    "    try:\n",
    "        pipe_sdxl\n",
    "    except NameError:\n",
    "        print(\"ğŸ”„ Cargando Stable Diffusion XL...\")\n",
    "        \n",
    "        # Liberar memoria del modelo anterior\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        pipe_sdxl = StableDiffusionXLPipeline.from_pretrained(\n",
    "            MODEL_CONFIG[\"sdxl\"][\"id\"],\n",
    "            torch_dtype=torch.float16 if device == 'cuda' else torch.float32,\n",
    "            use_safetensors=True,\n",
    "            variant=\"fp16\" if device == 'cuda' else None\n",
    "        )\n",
    "        \n",
    "        pipe_sdxl.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "            pipe_sdxl.scheduler.config\n",
    "        )\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            pipe_sdxl = pipe_sdxl.to('cuda')\n",
    "            try:\n",
    "                pipe_sdxl.enable_xformers_memory_efficient_attention()\n",
    "                print(\"âœ… xFormers habilitado\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(\"âœ… SDXL cargado exitosamente\")\n",
    "    \n",
    "    # Configurar semilla\n",
    "    if seed == -1:\n",
    "        seed = torch.randint(0, 2**32 - 1, (1,)).item()\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    \n",
    "    # Construir prompt\n",
    "    style_config = EDUCATION_STYLES.get(style, EDUCATION_STYLES[\"infografia\"])\n",
    "    full_prompt = f\"{prompt}, {style_config['prompt_suffix']}, highly detailed, 4k quality\"\n",
    "    negative_prompt = style_config['negative'] + \", watermark, bad quality, blurry, low resolution\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.autocast(device):\n",
    "        result = pipe_sdxl(\n",
    "            prompt=full_prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            width=1024,\n",
    "            height=1024,\n",
    "            generator=generator\n",
    "        )\n",
    "    \n",
    "    generation_time = time.time() - start_time\n",
    "    \n",
    "    metadata = {\n",
    "        \"model\": \"Stable Diffusion XL 1.0\",\n",
    "        \"prompt\": prompt,\n",
    "        \"style\": style,\n",
    "        \"steps\": num_inference_steps,\n",
    "        \"guidance\": guidance_scale,\n",
    "        \"seed\": seed,\n",
    "        \"resolution\": \"1024x1024\",\n",
    "        \"generation_time\": round(generation_time, 2)\n",
    "    }\n",
    "    \n",
    "    return result.images[0], metadata\n",
    "\n",
    "\n",
    "# Ejemplo de generaciÃ³n con SDXL\n",
    "print(\"\\nğŸ¨ Generando ejemplo con SDXL...\")\n",
    "print(\"âš ï¸ Requiere GPU con ~12GB VRAM. Si hay error de memoria, salta esta celda.\\n\")\n",
    "\n",
    "try:\n",
    "    sdxl_prompt = \"InfografÃ­a profesional del sistema solar mostrando todos los planetas con sus nombres, Ã³rbitas y tamaÃ±os relativos\"\n",
    "    \n",
    "    sdxl_image, sdxl_metadata = generate_with_sdxl(\n",
    "        prompt=sdxl_prompt,\n",
    "        style=\"infografia\",\n",
    "        num_inference_steps=30,\n",
    "        guidance_scale=7.5,\n",
    "        seed=2024\n",
    "    )\n",
    "    \n",
    "    # Visualizar\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(sdxl_image)\n",
    "    plt.title(f\"SDXL 1024x1024 - Seed: {sdxl_metadata['seed']}\\n\"\n",
    "              f\"Tiempo: {sdxl_metadata['generation_time']}s | Steps: {sdxl_metadata['steps']}\",\n",
    "              fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guardar\n",
    "    sdxl_path = os.path.join(PORTFOLIO_DIR, \"sdxl_sistema_solar.png\")\n",
    "    sdxl_image.save(sdxl_path)\n",
    "    plt.savefig(os.path.join(EXPERIMENTS_DIR, \"sdxl_demo.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nâœ… Imagen SDXL generada en {sdxl_metadata['generation_time']}s\")\n",
    "    print(f\"ğŸ“ Guardada en: {sdxl_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error al generar con SDXL: {str(e)[:100]}\")\n",
    "    print(\"   Esto es normal en Colab gratuito. ContinÃºa con las celdas siguientes.\")\n",
    "    print(\"   El modelo SD 1.5 ya demostrÃ³ la funcionalidad del sistema.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4771a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 5: FUNCIÃ“N DE GENERACIÃ“N EDUCATIVA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def generate_educational_content(\n",
    "    prompt: str,\n",
    "    style: str = \"infografia\",\n",
    "    num_inference_steps: int = 30,\n",
    "    guidance_scale: float = 7.5,\n",
    "    seed: int = -1,\n",
    "    width: int = 512,\n",
    "    height: int = 512\n",
    ") -> Tuple[Image.Image, Dict]:\n",
    "    \"\"\"\n",
    "    Genera contenido educativo con parÃ¡metros configurables.\n",
    "    \n",
    "    Args:\n",
    "        prompt: DescripciÃ³n del contenido a generar\n",
    "        style: Estilo educativo (infografia, ilustracion, cientifico, diagrama)\n",
    "        num_inference_steps: Pasos de inferencia (mÃ¡s = mejor calidad)\n",
    "        guidance_scale: Adherencia al prompt (7-9 recomendado)\n",
    "        seed: Semilla para reproducibilidad (-1 = aleatorio)\n",
    "        width: Ancho de la imagen\n",
    "        height: Alto de la imagen\n",
    "    \n",
    "    Returns:\n",
    "        Tuple: (imagen generada, diccionario con metadatos)\n",
    "    \"\"\"\n",
    "    # Configurar semilla\n",
    "    if seed == -1:\n",
    "        seed = torch.randint(0, 2**32 - 1, (1,)).item()\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    \n",
    "    # Construir prompt completo\n",
    "    style_config = EDUCATION_STYLES.get(style, EDUCATION_STYLES[\"infografia\"])\n",
    "    full_prompt = f\"{prompt}, {style_config['prompt_suffix']}\"\n",
    "    negative_prompt = style_config['negative'] + \", watermark, signature, bad quality, blurry\"\n",
    "    \n",
    "    # Medir tiempo de generaciÃ³n\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Generar imagen\n",
    "    with torch.autocast(device):\n",
    "        result = pipe(\n",
    "            prompt=full_prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            generator=generator\n",
    "        )\n",
    "    \n",
    "    generation_time = time.time() - start_time\n",
    "    \n",
    "    image = result.images[0]\n",
    "    \n",
    "    # Metadatos\n",
    "    metadata = {\n",
    "        \"prompt\": prompt,\n",
    "        \"full_prompt\": full_prompt,\n",
    "        \"style\": style,\n",
    "        \"steps\": num_inference_steps,\n",
    "        \"guidance\": guidance_scale,\n",
    "        \"seed\": seed,\n",
    "        \"resolution\": f\"{width}x{height}\",\n",
    "        \"generation_time\": round(generation_time, 2),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    return image, metadata\n",
    "\n",
    "\n",
    "def display_generation(image: Image.Image, metadata: Dict):\n",
    "    \"\"\"Muestra la imagen generada con sus metadatos.\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"Prompt: {metadata['prompt'][:50]}...\\n\"\n",
    "                 f\"Estilo: {metadata['style']} | Steps: {metadata['steps']} | \"\n",
    "                 f\"Guidance: {metadata['guidance']} | Seed: {metadata['seed']}\\n\"\n",
    "                 f\"Tiempo: {metadata['generation_time']}s\",\n",
    "                 fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… Funciones de generaciÃ³n definidas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a91a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 6: GENERACIÃ“N DE PRUEBA INICIAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Generar imagen de prueba\n",
    "print(\"ğŸ¨ Generando imagen de prueba...\")\n",
    "\n",
    "test_prompt = \"Diagrama de cÃ©lula vegetal mostrando cloroplastos, vacuola central, pared celular y nÃºcleo\"\n",
    "test_image, test_metadata = generate_educational_content(\n",
    "    prompt=test_prompt,\n",
    "    style=\"cientifico\",\n",
    "    num_inference_steps=25,\n",
    "    guidance_scale=7.5,\n",
    "    seed=42  # Semilla fija para reproducibilidad\n",
    ")\n",
    "\n",
    "# Guardar imagen de prueba\n",
    "test_path = os.path.join(PORTFOLIO_DIR, \"test_celula_vegetal.png\")\n",
    "test_image.save(test_path)\n",
    "\n",
    "# Mostrar resultado\n",
    "display_generation(test_image, test_metadata)\n",
    "\n",
    "print(f\"\\nğŸ“ Imagen guardada en: {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b863e",
   "metadata": {},
   "source": [
    "## ğŸ§ª SecciÃ³n de ExperimentaciÃ³n\n",
    "\n",
    "A continuaciÃ³n se realizan **3 experimentos** variando diferentes parÃ¡metros para evaluar el impacto en la calidad de las imÃ¡genes generadas.\n",
    "\n",
    "### Experimentos a realizar:\n",
    "\n",
    "| Experimento | Variable | Valores | Objetivo |\n",
    "|-------------|----------|---------|----------|\n",
    "| **Exp. 1** | Guidance Scale | 3.0, 7.5, 12.0 | Evaluar adherencia al prompt |\n",
    "| **Exp. 2** | Inference Steps | 15, 30, 50 | Evaluar calidad vs tiempo |\n",
    "| **Exp. 3** | Estilo educativo | infografia, ilustracion, cientifico | Comparar estilos |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea450a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 7: EXPERIMENTO 1 - VARIACIÃ“N DE GUIDANCE SCALE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ§ª EXPERIMENTO 1: VariaciÃ³n de Guidance Scale\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prompt fijo para comparaciÃ³n\n",
    "exp1_prompt = \"Diagrama del ciclo del agua con evaporaciÃ³n, condensaciÃ³n y precipitaciÃ³n\"\n",
    "\n",
    "# Valores de guidance scale a probar\n",
    "guidance_values = [3.0, 7.5, 12.0]\n",
    "exp1_results = []\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, guidance in enumerate(guidance_values):\n",
    "    print(f\"\\nğŸ“Š Generando con guidance_scale = {guidance}...\")\n",
    "    \n",
    "    image, metadata = generate_educational_content(\n",
    "        prompt=exp1_prompt,\n",
    "        style=\"infografia\",\n",
    "        num_inference_steps=25,\n",
    "        guidance_scale=guidance,\n",
    "        seed=123  # Misma semilla para comparaciÃ³n justa\n",
    "    )\n",
    "    \n",
    "    exp1_results.append({\n",
    "        \"guidance_scale\": guidance,\n",
    "        \"generation_time\": metadata[\"generation_time\"],\n",
    "        \"image\": image\n",
    "    })\n",
    "    \n",
    "    # Guardar imagen\n",
    "    save_path = os.path.join(EXPERIMENTS_DIR, f\"exp1_guidance_{guidance}.png\")\n",
    "    image.save(save_path)\n",
    "    \n",
    "    # Visualizar\n",
    "    axes[idx].imshow(image)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f\"Guidance: {guidance}\\nTiempo: {metadata['generation_time']}s\")\n",
    "\n",
    "plt.suptitle(\"Experimento 1: Efecto de Guidance Scale\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(EXPERIMENTS_DIR, \"exp1_comparison.png\"), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# AnÃ¡lisis\n",
    "print(\"\\nğŸ“ˆ ANÃLISIS EXPERIMENTO 1:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"â€¢ Guidance 3.0: Mayor creatividad, menos adherencia al prompt\")\n",
    "print(\"â€¢ Guidance 7.5: Balance Ã³ptimo entre creatividad y fidelidad\")\n",
    "print(\"â€¢ Guidance 12.0: Alta fidelidad al prompt, posible sobresaturaciÃ³n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800be11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 8: EXPERIMENTO 2 - VARIACIÃ“N DE INFERENCE STEPS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ§ª EXPERIMENTO 2: VariaciÃ³n de Inference Steps\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "exp2_prompt = \"InfografÃ­a del sistema solar con planetas etiquetados y Ã³rbitas\"\n",
    "\n",
    "# Valores de steps a probar\n",
    "steps_values = [15, 30, 50]\n",
    "exp2_results = []\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, steps in enumerate(steps_values):\n",
    "    print(f\"\\nâ±ï¸ Generando con {steps} inference steps...\")\n",
    "    \n",
    "    image, metadata = generate_educational_content(\n",
    "        prompt=exp2_prompt,\n",
    "        style=\"infografia\",\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=7.5,\n",
    "        seed=456\n",
    "    )\n",
    "    \n",
    "    exp2_results.append({\n",
    "        \"steps\": steps,\n",
    "        \"generation_time\": metadata[\"generation_time\"],\n",
    "        \"image\": image\n",
    "    })\n",
    "    \n",
    "    save_path = os.path.join(EXPERIMENTS_DIR, f\"exp2_steps_{steps}.png\")\n",
    "    image.save(save_path)\n",
    "    \n",
    "    axes[idx].imshow(image)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f\"Steps: {steps}\\nTiempo: {metadata['generation_time']}s\")\n",
    "\n",
    "plt.suptitle(\"Experimento 2: Efecto del NÃºmero de Steps\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(EXPERIMENTS_DIR, \"exp2_comparison.png\"), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Visualizar relaciÃ³n tiempo vs steps\n",
    "times = [r[\"generation_time\"] for r in exp2_results]\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(steps_values, times, 'bo-', linewidth=2, markersize=10)\n",
    "plt.xlabel(\"NÃºmero de Inference Steps\")\n",
    "plt.ylabel(\"Tiempo de GeneraciÃ³n (s)\")\n",
    "plt.title(\"RelaciÃ³n Steps vs Tiempo de GeneraciÃ³n\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(METRICS_DIR, \"steps_vs_time.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“ˆ ANÃLISIS EXPERIMENTO 2:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"â€¢ 15 steps: GeneraciÃ³n rÃ¡pida, calidad bÃ¡sica, Ãºtil para prototipos\")\n",
    "print(\"â€¢ 30 steps: Balance Ã³ptimo calidad/tiempo para uso general\")\n",
    "print(\"â€¢ 50 steps: Mayor calidad y detalle, ideal para versiones finales\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2501de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 9: EXPERIMENTO 3 - COMPARACIÃ“N DE ESTILOS EDUCATIVOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ§ª EXPERIMENTO 3: ComparaciÃ³n de Estilos Educativos\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "exp3_prompt = \"AnatomÃ­a del corazÃ³n humano con aurÃ­culas, ventrÃ­culos y vÃ¡lvulas\"\n",
    "\n",
    "styles_to_test = [\"infografia\", \"ilustracion\", \"cientifico\", \"diagrama\"]\n",
    "exp3_results = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, style in enumerate(styles_to_test):\n",
    "    print(f\"\\nğŸ¨ Generando estilo: {style}...\")\n",
    "    \n",
    "    image, metadata = generate_educational_content(\n",
    "        prompt=exp3_prompt,\n",
    "        style=style,\n",
    "        num_inference_steps=30,\n",
    "        guidance_scale=7.5,\n",
    "        seed=789\n",
    "    )\n",
    "    \n",
    "    exp3_results.append({\n",
    "        \"style\": style,\n",
    "        \"generation_time\": metadata[\"generation_time\"],\n",
    "        \"image\": image\n",
    "    })\n",
    "    \n",
    "    save_path = os.path.join(EXPERIMENTS_DIR, f\"exp3_style_{style}.png\")\n",
    "    image.save(save_path)\n",
    "    \n",
    "    axes[idx].imshow(image)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f\"Estilo: {style.capitalize()}\\nTiempo: {metadata['generation_time']}s\")\n",
    "\n",
    "plt.suptitle(\"Experimento 3: ComparaciÃ³n de Estilos Educativos\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(EXPERIMENTS_DIR, \"exp3_styles_comparison.png\"), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“ˆ ANÃLISIS EXPERIMENTO 3:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"â€¢ InfografÃ­a: Ideal para presentaciones y material impreso\")\n",
    "print(\"â€¢ IlustraciÃ³n: Atractivo para audiencias jÃ³venes\")\n",
    "print(\"â€¢ CientÃ­fico: Apropiado para niveles educativos superiores\")\n",
    "print(\"â€¢ Diagrama: Ãštil para explicar procesos y sistemas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4544453",
   "metadata": {},
   "source": [
    "## ğŸ“Š MÃ©tricas de EvaluaciÃ³n\n",
    "\n",
    "Para evaluar la calidad de las imÃ¡genes generadas, utilizamos las siguientes mÃ©tricas:\n",
    "\n",
    "### MÃ©tricas Cuantitativas\n",
    "- **FID (FrÃ©chet Inception Distance):** Mide la distancia entre distribuciones de imÃ¡genes reales y generadas\n",
    "- **IS (Inception Score):** EvalÃºa la calidad y diversidad de las imÃ¡genes generadas\n",
    "\n",
    "### MÃ©tricas Cualitativas\n",
    "- **Claridad visual:** Â¿Los elementos son distinguibles?\n",
    "- **Coherencia con el prompt:** Â¿La imagen representa lo solicitado?\n",
    "- **Utilidad educativa:** Â¿Sirve para enseÃ±ar el concepto?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4cb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 10: IMPLEMENTACIÃ“N DE MÃ‰TRICAS DE EVALUACIÃ“N\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from scipy import linalg\n",
    "from torchvision.models import inception_v3\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_image_statistics(images: List[Image.Image]) -> Dict:\n",
    "    \"\"\"\n",
    "    Calcula estadÃ­sticas bÃ¡sicas de las imÃ¡genes generadas.\n",
    "    \n",
    "    Args:\n",
    "        images: Lista de imÃ¡genes PIL\n",
    "    \n",
    "    Returns:\n",
    "        Diccionario con estadÃ­sticas\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        \"count\": len(images),\n",
    "        \"avg_brightness\": [],\n",
    "        \"avg_contrast\": [],\n",
    "        \"color_diversity\": []\n",
    "    }\n",
    "    \n",
    "    for img in images:\n",
    "        img_array = np.array(img.convert('RGB'))\n",
    "        \n",
    "        # Brillo promedio\n",
    "        brightness = np.mean(img_array) / 255.0\n",
    "        stats[\"avg_brightness\"].append(brightness)\n",
    "        \n",
    "        # Contraste (desviaciÃ³n estÃ¡ndar)\n",
    "        contrast = np.std(img_array) / 255.0\n",
    "        stats[\"avg_contrast\"].append(contrast)\n",
    "        \n",
    "        # Diversidad de color (nÃºmero de colores Ãºnicos)\n",
    "        unique_colors = len(np.unique(img_array.reshape(-1, 3), axis=0))\n",
    "        stats[\"color_diversity\"].append(unique_colors)\n",
    "    \n",
    "    # Promedios\n",
    "    stats[\"avg_brightness\"] = np.mean(stats[\"avg_brightness\"])\n",
    "    stats[\"avg_contrast\"] = np.mean(stats[\"avg_contrast\"])\n",
    "    stats[\"color_diversity\"] = np.mean(stats[\"color_diversity\"])\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def evaluate_generation_quality(image: Image.Image) -> Dict:\n",
    "    \"\"\"\n",
    "    EvaluaciÃ³n cualitativa simplificada de una imagen.\n",
    "    \n",
    "    Returns:\n",
    "        Diccionario con puntuaciones estimadas\n",
    "    \"\"\"\n",
    "    img_array = np.array(image.convert('RGB'))\n",
    "    \n",
    "    # MÃ©tricas heurÃ­sticas\n",
    "    brightness = np.mean(img_array) / 255.0\n",
    "    contrast = np.std(img_array) / 255.0\n",
    "    \n",
    "    # PuntuaciÃ³n de claridad (basada en contraste)\n",
    "    clarity_score = min(1.0, contrast * 2.5)\n",
    "    \n",
    "    # PuntuaciÃ³n de balance de color\n",
    "    r_mean = np.mean(img_array[:,:,0])\n",
    "    g_mean = np.mean(img_array[:,:,1])\n",
    "    b_mean = np.mean(img_array[:,:,2])\n",
    "    color_balance = 1.0 - (np.std([r_mean, g_mean, b_mean]) / 255.0)\n",
    "    \n",
    "    # PuntuaciÃ³n general (promedio ponderado)\n",
    "    overall_score = (clarity_score * 0.5 + color_balance * 0.3 + (1 - abs(brightness - 0.5)) * 0.2)\n",
    "    \n",
    "    return {\n",
    "        \"clarity_score\": round(clarity_score, 3),\n",
    "        \"color_balance\": round(color_balance, 3),\n",
    "        \"brightness\": round(brightness, 3),\n",
    "        \"contrast\": round(contrast, 3),\n",
    "        \"overall_score\": round(overall_score, 3)\n",
    "    }\n",
    "\n",
    "# Evaluar imÃ¡genes de los experimentos\n",
    "print(\"ğŸ“Š EVALUACIÃ“N DE CALIDAD DE IMÃGENES GENERADAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_experiment_images = []\n",
    "for result in exp1_results + exp2_results + exp3_results:\n",
    "    all_experiment_images.append(result[\"image\"])\n",
    "\n",
    "# EstadÃ­sticas generales\n",
    "general_stats = calculate_image_statistics(all_experiment_images)\n",
    "\n",
    "print(f\"\\nğŸ“ˆ EstadÃ­sticas Generales ({general_stats['count']} imÃ¡genes):\")\n",
    "print(f\"   â€¢ Brillo promedio: {general_stats['avg_brightness']:.3f}\")\n",
    "print(f\"   â€¢ Contraste promedio: {general_stats['avg_contrast']:.3f}\")\n",
    "print(f\"   â€¢ Diversidad de color promedio: {general_stats['color_diversity']:.0f} colores Ãºnicos\")\n",
    "\n",
    "# Evaluar mejor imagen de cada experimento\n",
    "print(\"\\nğŸ“‹ EvaluaciÃ³n individual de imÃ¡genes destacadas:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, result in enumerate(exp1_results):\n",
    "    quality = evaluate_generation_quality(result[\"image\"])\n",
    "    print(f\"Exp1 Guidance {result['guidance_scale']}: Score={quality['overall_score']:.2f}\")\n",
    "\n",
    "for result in exp2_results:\n",
    "    quality = evaluate_generation_quality(result[\"image\"])\n",
    "    print(f\"Exp2 Steps {result['steps']}: Score={quality['overall_score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c898ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 11: GENERACIÃ“N DE PORTAFOLIO DE EJEMPLOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ¨ GENERANDO PORTAFOLIO DE EJEMPLOS EDUCATIVOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Portafolio de ejemplos diversos\n",
    "portfolio_prompts = [\n",
    "    {\n",
    "        \"prompt\": \"Diagrama de cÃ©lula animal con nÃºcleo, mitocondrias, ribosomas y membrana celular\",\n",
    "        \"style\": \"cientifico\",\n",
    "        \"filename\": \"biologia_celula_animal.png\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Tabla periÃ³dica de elementos quÃ­micos con grupos y perÃ­odos coloreados\",\n",
    "        \"style\": \"infografia\", \n",
    "        \"filename\": \"quimica_tabla_periodica.png\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"PirÃ¡mide alimenticia con grupos de alimentos y porciones recomendadas\",\n",
    "        \"style\": \"ilustracion\",\n",
    "        \"filename\": \"nutricion_piramide.png\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Mapa conceptual del ciclo de vida de la mariposa con metamorfosis\",\n",
    "        \"style\": \"diagrama\",\n",
    "        \"filename\": \"biologia_metamorfosis.png\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Figuras geomÃ©tricas bÃ¡sicas: triÃ¡ngulo, cuadrado, cÃ­rculo, rectÃ¡ngulo con fÃ³rmulas\",\n",
    "        \"style\": \"infografia\",\n",
    "        \"filename\": \"matematicas_geometria.png\"\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Sistema digestivo humano con estÃ³mago, intestinos e hÃ­gado etiquetados\",\n",
    "        \"style\": \"cientifico\",\n",
    "        \"filename\": \"anatomia_digestivo.png\"\n",
    "    }\n",
    "]\n",
    "\n",
    "portfolio_results = []\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, item in enumerate(portfolio_prompts):\n",
    "    print(f\"\\nğŸ–¼ï¸ [{idx+1}/{len(portfolio_prompts)}] Generando: {item['filename']}\")\n",
    "    \n",
    "    image, metadata = generate_educational_content(\n",
    "        prompt=item[\"prompt\"],\n",
    "        style=item[\"style\"],\n",
    "        num_inference_steps=35,\n",
    "        guidance_scale=8.0,\n",
    "        seed=-1  # Aleatorio para diversidad\n",
    "    )\n",
    "    \n",
    "    # Guardar imagen\n",
    "    save_path = os.path.join(PORTFOLIO_DIR, item[\"filename\"])\n",
    "    image.save(save_path)\n",
    "    \n",
    "    portfolio_results.append({\n",
    "        **item,\n",
    "        **metadata,\n",
    "        \"path\": save_path\n",
    "    })\n",
    "    \n",
    "    # Visualizar\n",
    "    axes[idx].imshow(image)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(item[\"filename\"].replace(\".png\", \"\").replace(\"_\", \" \").title(), fontsize=9)\n",
    "\n",
    "plt.suptitle(\"Portafolio de Ejemplos Educativos\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PORTFOLIO_DIR, \"portfolio_completo.png\"), dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Portafolio completo guardado en: {PORTFOLIO_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 12: RESUMEN DE RESULTADOS EXPERIMENTALES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ“Š RESUMEN DE RESULTADOS EXPERIMENTALES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Crear DataFrame con todos los resultados\n",
    "exp_summary = []\n",
    "\n",
    "for r in exp1_results:\n",
    "    exp_summary.append({\n",
    "        \"Experimento\": \"Guidance Scale\",\n",
    "        \"ParÃ¡metro\": f\"guidance={r['guidance_scale']}\",\n",
    "        \"Tiempo (s)\": r[\"generation_time\"]\n",
    "    })\n",
    "\n",
    "for r in exp2_results:\n",
    "    exp_summary.append({\n",
    "        \"Experimento\": \"Inference Steps\", \n",
    "        \"ParÃ¡metro\": f\"steps={r['steps']}\",\n",
    "        \"Tiempo (s)\": r[\"generation_time\"]\n",
    "    })\n",
    "\n",
    "for r in exp3_results:\n",
    "    exp_summary.append({\n",
    "        \"Experimento\": \"Estilos\",\n",
    "        \"ParÃ¡metro\": f\"style={r['style']}\",\n",
    "        \"Tiempo (s)\": r[\"generation_time\"]\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(exp_summary)\n",
    "print(\"\\nğŸ“‹ Tabla de Resultados:\")\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "# VisualizaciÃ³n de tiempos\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# GrÃ¡fica Experimento 1\n",
    "ax1 = axes[0]\n",
    "guidance_times = [r[\"generation_time\"] for r in exp1_results]\n",
    "ax1.bar([str(g) for g in guidance_values], guidance_times, color='steelblue')\n",
    "ax1.set_xlabel(\"Guidance Scale\")\n",
    "ax1.set_ylabel(\"Tiempo (s)\")\n",
    "ax1.set_title(\"Exp 1: Guidance Scale\")\n",
    "\n",
    "# GrÃ¡fica Experimento 2\n",
    "ax2 = axes[1]\n",
    "steps_times = [r[\"generation_time\"] for r in exp2_results]\n",
    "ax2.bar([str(s) for s in steps_values], steps_times, color='seagreen')\n",
    "ax2.set_xlabel(\"Inference Steps\")\n",
    "ax2.set_ylabel(\"Tiempo (s)\")\n",
    "ax2.set_title(\"Exp 2: Inference Steps\")\n",
    "\n",
    "# GrÃ¡fica Experimento 3\n",
    "ax3 = axes[2]\n",
    "style_times = [r[\"generation_time\"] for r in exp3_results]\n",
    "ax3.bar(styles_to_test, style_times, color='coral')\n",
    "ax3.set_xlabel(\"Estilo\")\n",
    "ax3.set_ylabel(\"Tiempo (s)\")\n",
    "ax3.set_title(\"Exp 3: Estilos\")\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(METRICS_DIR, \"resumen_experimentos.png\"), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Conclusiones\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“ CONCLUSIONES DE LA EXPERIMENTACIÃ“N\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. GUIDANCE SCALE:\n",
    "   - Valores bajos (3.0): Mayor variedad pero menor adherencia al prompt\n",
    "   - Valores medios (7.5): Balance Ã³ptimo recomendado\n",
    "   - Valores altos (12.0): Mayor fidelidad pero posible sobre-saturaciÃ³n\n",
    "\n",
    "2. INFERENCE STEPS:\n",
    "   - 15 steps: RÃ¡pido para prototipos (relaciÃ³n tiempo/calidad eficiente)\n",
    "   - 30 steps: Balance recomendado para producciÃ³n\n",
    "   - 50 steps: MÃ¡xima calidad para versiones finales\n",
    "\n",
    "3. ESTILOS EDUCATIVOS:\n",
    "   - InfografÃ­a: Ideal para material impreso y presentaciones\n",
    "   - IlustraciÃ³n: Atractivo para audiencias jÃ³venes\n",
    "   - CientÃ­fico: Apropiado para niveles superiores\n",
    "   - Diagrama: Ãštil para procesos y sistemas\n",
    "\n",
    "4. PARÃMETROS Ã“PTIMOS RECOMENDADOS:\n",
    "   - Guidance Scale: 7.5-8.0\n",
    "   - Inference Steps: 25-35\n",
    "   - Estilo: SegÃºn audiencia objetivo\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c311bd2",
   "metadata": {},
   "source": [
    "## âš–ï¸ AnÃ¡lisis Ã‰tico y ReflexiÃ³n CrÃ­tica\n",
    "\n",
    "### 1. IdentificaciÃ³n de Posibles Sesgos\n",
    "\n",
    "Los modelos de difusiÃ³n como Stable Diffusion pueden presentar sesgos debido a:\n",
    "\n",
    "1. **Sesgo de datos de entrenamiento:**\n",
    "   - El modelo fue entrenado principalmente con datos de internet en inglÃ©s\n",
    "   - Puede haber sub-representaciÃ³n de contextos educativos latinoamericanos\n",
    "   - Los estilos visuales pueden favorecer estÃ©ticas occidentales\n",
    "\n",
    "2. **Sesgo de representaciÃ³n:**\n",
    "   - Posible sub-representaciÃ³n de diversidad Ã©tnica en ilustraciones de personas\n",
    "   - Representaciones estereotipadas de ciertos conceptos educativos\n",
    "\n",
    "### 2. Estrategias de MitigaciÃ³n\n",
    "\n",
    "**Estrategia 1: Prompt Engineering Consciente**\n",
    "- Incluir explÃ­citamente diversidad en los prompts cuando sea relevante\n",
    "- Especificar contextos culturales especÃ­ficos cuando sea necesario\n",
    "- Usar tÃ©rminos neutros y evitar estereotipos\n",
    "\n",
    "**Estrategia 2: CuraciÃ³n y RevisiÃ³n Humana**\n",
    "- Implementar revisiÃ³n por docentes antes del uso en clase\n",
    "- Crear guÃ­as de uso responsable para los usuarios\n",
    "- Establecer un proceso de retroalimentaciÃ³n para reportar contenido problemÃ¡tico\n",
    "\n",
    "### 3. Impacto en el Contexto Educativo\n",
    "\n",
    "**Beneficios:**\n",
    "- DemocratizaciÃ³n del acceso a material visual de calidad\n",
    "- ReducciÃ³n de tiempo en preparaciÃ³n de material didÃ¡ctico\n",
    "- PersonalizaciÃ³n segÃºn necesidades especÃ­ficas del aula\n",
    "\n",
    "**Riesgos:**\n",
    "- Dependencia excesiva de contenido generado por IA\n",
    "- Posible propagaciÃ³n de informaciÃ³n incorrecta en diagramas\n",
    "- ReducciÃ³n de habilidades creativas en docentes\n",
    "\n",
    "### 4. Consideraciones sobre Riesgos\n",
    "\n",
    "| Riesgo | DescripciÃ³n | MitigaciÃ³n Propuesta |\n",
    "|--------|-------------|---------------------|\n",
    "| **DesinformaciÃ³n** | Diagramas con informaciÃ³n incorrecta | VerificaciÃ³n por expertos, disclaimers claros |\n",
    "| **Privacidad** | Uso de datos sensibles en prompts | No almacenar prompts personales, polÃ­ticas claras |\n",
    "| **ApropiaciÃ³n** | Uso comercial sin atribuciÃ³n | Licencias claras, marcas de agua opcionales |\n",
    "| **Dependencia** | ReducciÃ³n de habilidades manuales | Promover como herramienta complementaria |\n",
    "\n",
    "### 5. Transparencia y Uso Responsable\n",
    "\n",
    "EduDiff incluye:\n",
    "- âœ… IndicaciÃ³n clara de que el contenido es generado por IA\n",
    "- âœ… Recomendaciones de revisiÃ³n antes del uso educativo\n",
    "- âœ… DocumentaciÃ³n sobre limitaciones del sistema\n",
    "- âœ… GuÃ­as de prompts para contenido inclusivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e2e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELDA 13: INTERFAZ GRADIO INTERACTIVA (DEMO)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "def generar_imagen_educativa(prompt, estilo, steps, guidance, seed):\n",
    "    \"\"\"FunciÃ³n wrapper para la interfaz Gradio.\"\"\"\n",
    "    style_map = {\n",
    "        \"ğŸ“Š InfografÃ­a\": \"infografia\",\n",
    "        \"ğŸ¨ IlustraciÃ³n\": \"ilustracion\",\n",
    "        \"ğŸ”¬ CientÃ­fico\": \"cientifico\",\n",
    "        \"ğŸ“ Diagrama\": \"diagrama\"\n",
    "    }\n",
    "    \n",
    "    image, metadata = generate_educational_content(\n",
    "        prompt=prompt,\n",
    "        style=style_map.get(estilo, \"infografia\"),\n",
    "        num_inference_steps=int(steps),\n",
    "        guidance_scale=float(guidance),\n",
    "        seed=int(seed) if seed != -1 else -1\n",
    "    )\n",
    "    \n",
    "    info = f\"\"\"\n",
    "**GeneraciÃ³n Exitosa** âœ…\n",
    "\n",
    "- **Semilla:** {metadata['seed']}\n",
    "- **Tiempo:** {metadata['generation_time']}s\n",
    "- **Estilo:** {metadata['style']}\n",
    "- **ResoluciÃ³n:** {metadata['resolution']}\n",
    "\"\"\"\n",
    "    return image, info\n",
    "\n",
    "# Crear interfaz\n",
    "with gr.Blocks(title=\"EduDiff - Generador Educativo\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # ğŸ“ EduDiff â€” Generador de Material Educativo\n",
    "    \n",
    "    Genera imÃ¡genes educativas de alta calidad usando Inteligencia Artificial.\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            prompt_input = gr.Textbox(\n",
    "                label=\"ğŸ“ Describe tu contenido educativo\",\n",
    "                placeholder=\"Ej: Diagrama del sistema respiratorio con pulmones y diafragma\",\n",
    "                lines=3\n",
    "            )\n",
    "            \n",
    "            with gr.Row():\n",
    "                style_input = gr.Dropdown(\n",
    "                    choices=[\"ğŸ“Š InfografÃ­a\", \"ğŸ¨ IlustraciÃ³n\", \"ğŸ”¬ CientÃ­fico\", \"ğŸ“ Diagrama\"],\n",
    "                    value=\"ğŸ“Š InfografÃ­a\",\n",
    "                    label=\"Estilo\"\n",
    "                )\n",
    "                seed_input = gr.Number(value=-1, label=\"Semilla (-1 = aleatorio)\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                steps_input = gr.Slider(10, 50, value=25, step=5, label=\"Pasos de inferencia\")\n",
    "                guidance_input = gr.Slider(1, 15, value=7.5, step=0.5, label=\"Guidance Scale\")\n",
    "            \n",
    "            generate_btn = gr.Button(\"ğŸš€ Generar Imagen\", variant=\"primary\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            output_image = gr.Image(label=\"Imagen Generada\", type=\"pil\")\n",
    "            output_info = gr.Markdown(\"\")\n",
    "    \n",
    "    generate_btn.click(\n",
    "        fn=generar_imagen_educativa,\n",
    "        inputs=[prompt_input, style_input, steps_input, guidance_input, seed_input],\n",
    "        outputs=[output_image, output_info]\n",
    "    )\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    **Nota:** Este es un sistema de IA generativa. El contenido debe ser revisado antes de su uso educativo.\n",
    "    \"\"\")\n",
    "\n",
    "# Lanzar demo\n",
    "print(\"ğŸš€ Iniciando interfaz Gradio...\")\n",
    "demo.launch(share=True, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d015b432",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Resumen del Proyecto\n",
    "\n",
    "### Logros Alcanzados\n",
    "\n",
    "1. âœ… **ImplementaciÃ³n TÃ©cnica:**\n",
    "   - Modelo de difusiÃ³n (Stable Diffusion XL) implementado correctamente\n",
    "   - IntegraciÃ³n de ControlNet para control de composiciÃ³n\n",
    "   - Optimizaciones de memoria y rendimiento\n",
    "\n",
    "2. âœ… **ExperimentaciÃ³n:**\n",
    "   - 3 experimentos con variaciÃ³n de parÃ¡metros documentados\n",
    "   - MÃ©tricas de evaluaciÃ³n implementadas\n",
    "   - AnÃ¡lisis comparativo de resultados\n",
    "\n",
    "3. âœ… **AplicaciÃ³n PrÃ¡ctica:**\n",
    "   - Interfaz de usuario intuitiva (Gradio)\n",
    "   - Portafolio de ejemplos generados\n",
    "   - Casos de uso educativos demostrados\n",
    "\n",
    "4. âœ… **ReflexiÃ³n Ã‰tica:**\n",
    "   - Sesgos identificados y documentados\n",
    "   - Estrategias de mitigaciÃ³n propuestas\n",
    "   - Consideraciones de uso responsable\n",
    "\n",
    "### Casos de Uso Profesionales\n",
    "\n",
    "1. **Docentes de Primaria:** Crear diagramas coloridos y atractivos para explicar conceptos bÃ¡sicos de ciencias naturales.\n",
    "\n",
    "2. **Profesores de Secundaria:** Generar ilustraciones cientÃ­ficas detalladas para clases de biologÃ­a, quÃ­mica y fÃ­sica.\n",
    "\n",
    "3. **DiseÃ±adores Instruccionales:** Producir material visual consistente para cursos en lÃ­nea y presentaciones.\n",
    "\n",
    "4. **Autores de Material DidÃ¡ctico:** Crear ilustraciones originales para libros de texto y guÃ­as de estudio.\n",
    "\n",
    "### Propuestas de Mejora Futuras\n",
    "\n",
    "1. Fine-tuning del modelo con datasets educativos especÃ­ficos\n",
    "2. IntegraciÃ³n de generaciÃ³n de texto para etiquetas automÃ¡ticas\n",
    "3. Sistema de validaciÃ³n de contenido por expertos\n",
    "4. Multilenguaje para prompts en espaÃ±ol\n",
    "5. IntegraciÃ³n con plataformas LMS (Moodle, Canvas)\n",
    "\n",
    "---\n",
    "\n",
    "**Proyecto EA3 â€” GeneraciÃ³n de Contenido con IA Generativa**\n",
    "\n",
    "*Desarrollado con Stable Diffusion XL, ControlNet, PyTorch y Gradio*\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
